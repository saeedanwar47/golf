{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "[{'scores': tensor([0.4785, 0.4379, 0.4761], device='cuda:0'), 'labels': ['a cat', 'a cat', 'a remote control'], 'boxes': tensor([[344.6980,  23.1083, 637.1817, 374.2748],\n",
      "        [ 12.2695,  51.9101, 316.8565, 472.4348],\n",
      "        [ 38.5854,  70.0091, 176.7766, 118.1754]], device='cuda:0')}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device: \", device)\n",
    "\n",
    "model_id = \"IDEA-Research/grounding-dino-tiny\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)\n",
    "\n",
    "image_url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "# Check for cats and remote controls\n",
    "text = \"a cat. a remote control.\"\n",
    "\n",
    "inputs = processor(images=image, text=text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "results = processor.post_process_grounded_object_detection(\n",
    "    outputs,\n",
    "    inputs.input_ids,\n",
    "    box_threshold=0.4,\n",
    "    text_threshold=0.3,\n",
    "    target_sizes=[image.size[::-1]]\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'scores': tensor([0.4785, 0.4379, 0.4761], device='cuda:0'),\n",
       "  'labels': ['a cat', 'a cat', 'a remote control'],\n",
       "  'boxes': tensor([[344.6980,  23.1083, 637.1817, 374.2748],\n",
       "          [ 12.2695,  51.9101, 316.8565, 472.4348],\n",
       "          [ 38.5854,  70.0091, 176.7766, 118.1754]], device='cuda:0')}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'scores': tensor([0.8204, 0.4161, 0.4141], device='cuda:0'), 'labels': ['person', 'golf stick', 'golf stick'], 'boxes': tensor([[356.8754,  27.0503, 719.2704, 738.0521],\n",
      "        [361.2272, 368.1149, 514.1579, 680.6292],\n",
      "        [361.8553, 414.1008, 480.0444, 679.3328]], device='cuda:0')}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device: \", device)\n",
    "\n",
    "model_id = \"IDEA-Research/grounding-dino-base\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)\n",
    "\n",
    "# Replace this with your local image path\n",
    "# image_path = \"/path/to/your/image.jpg\"\n",
    "image_path = \"/home/ammara/Documents/helper_code/extracted_frames/movie_3/frame_0.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Check for cats and remote controls\n",
    "text = \"person. golf stick.\"\n",
    "\n",
    "inputs = processor(images=image, text=text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "results = processor.post_process_grounded_object_detection(\n",
    "    outputs,\n",
    "    inputs.input_ids,\n",
    "    box_threshold=0.4,\n",
    "    text_threshold=0.3,\n",
    "    target_sizes=[image.size[::-1]]\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped 2 golf stick images.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the original image\n",
    "original_image = Image.open(\"/home/ammara/Documents/helper_code/extracted_frames/movie_3/frame_0.jpg\")\n",
    "\n",
    "# Recreating the results as a Python dictionary with torch tensors\n",
    "results = [{\n",
    "    'scores': torch.tensor([0.8204, 0.4161, 0.4141], device='cuda:0'),\n",
    "    'labels': ['person', 'golf stick', 'golf stick'],\n",
    "    'boxes': torch.tensor([[356.8754, 27.0503, 719.2704, 738.0521],\n",
    "                           [361.2272, 368.1149, 514.1579, 680.6292],\n",
    "                           [361.8553, 414.1008, 480.0444, 679.3328]], device='cuda:0')\n",
    "}]\n",
    "\n",
    "# Function to crop image based on bounding box\n",
    "def crop_image(image, box):\n",
    "    return image.crop(box)\n",
    "\n",
    "# Find all 'golf stick' boxes\n",
    "golf_stick_boxes = [box.cpu().numpy() for box, label in zip(results[0]['boxes'], results[0]['labels']) if label == 'golf stick']\n",
    "\n",
    "# Crop images for each golf stick box\n",
    "cropped_images = []\n",
    "for i, box in enumerate(golf_stick_boxes):\n",
    "    # Convert box coordinates to integers\n",
    "    box = [int(coord) for coord in box]\n",
    "    cropped_image = crop_image(original_image, box)\n",
    "    cropped_images.append(cropped_image)\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cropped_image.save(f\"golf_stick_{i+1}.jpg\")\n",
    "\n",
    "print(f\"Cropped {len(cropped_images)} golf stick images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped 2 golf stick images and saved their information.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Assuming you have the original image\n",
    "original_image = Image.open(\"/home/ammara/Documents/helper_code/extracted_frames/movie_3/frame_0.jpg\")\n",
    "\n",
    "# Recreating the results as a Python dictionary with torch tensors\n",
    "results = [{\n",
    "    'scores': torch.tensor([0.8204, 0.4161, 0.4141], device='cuda:0'),\n",
    "    'labels': ['person', 'golf stick', 'golf stick'],\n",
    "    'boxes': torch.tensor([[356.8754, 27.0503, 719.2704, 738.0521],\n",
    "                           [361.2272, 368.1149, 514.1579, 680.6292],\n",
    "                           [361.8553, 414.1008, 480.0444, 679.3328]], device='cuda:0')\n",
    "}]\n",
    "\n",
    "# Function to crop image based on bounding box\n",
    "def crop_image(image, box):\n",
    "    return image.crop(box)\n",
    "\n",
    "# Find all 'golf stick' boxes\n",
    "golf_stick_boxes = [(box.cpu().numpy(), score.item()) \n",
    "                    for box, label, score in zip(results[0]['boxes'], results[0]['labels'], results[0]['scores']) \n",
    "                    if label == 'golf stick']\n",
    "\n",
    "# Create a directory to save results\n",
    "os.makedirs(\"golf_stick_results\", exist_ok=True)\n",
    "\n",
    "# Crop images for each golf stick box\n",
    "for i, (box, score) in enumerate(golf_stick_boxes):\n",
    "    # Convert box coordinates to integers\n",
    "    box = [int(coord) for coord in box]\n",
    "    cropped_image = crop_image(original_image, box)\n",
    "    \n",
    "    # Save the cropped image\n",
    "    image_filename = f\"golf_stick_{i+1}.jpg\"\n",
    "    cropped_image.save(os.path.join(\"golf_stick_results\", image_filename))\n",
    "    \n",
    "    # Save the box information\n",
    "    box_info = {\n",
    "        \"box\": box,\n",
    "        \"score\": score,\n",
    "        \"label\": \"golf stick\"\n",
    "    }\n",
    "    json_filename = f\"golf_stick_{i+1}_info.json\"\n",
    "    with open(os.path.join(\"golf_stick_results\", json_filename), 'w') as f:\n",
    "        json.dump(box_info, f, indent=4)\n",
    "\n",
    "print(f\"Cropped {len(golf_stick_boxes)} golf stick images and saved their information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
